AKA Surprisal, Information Content, Shannon Information
See: [[Mutual Information]]

Let $X$ be a random variable with [[Discrete Probability Density Function|probability mass function]] $p_{X}(x)$, then the information content of measuring $X$ as $x$ is:$$
I_{X}(x):=-\log p_{X}(x)
$$