An estimator $\hat{\theta}$ for a parameter $\theta$ is unbiased if:
$$
\mathbb{E}(\hat{\theta}) = \theta
$$
That is, for continuous [[Random Variable|random variables]]:
$$
\int \hat{\theta}\cdot f(x)dx = \theta
$$
for a [[Probability Density Function|probability density function]] $f$.
And, for discrete random variables:
$$
\sum \hat{\theta}\cdot P(x) = \theta
$$
for a [[Discrete Probability Density Function|probability mass function]] $P$.

